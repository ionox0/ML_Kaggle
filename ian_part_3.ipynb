{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "# Classification utils\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Set ipython's max row / column display\n",
    "pd.set_option('display.max_row', 20)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "\n",
    "train = pd.read_csv('data.csv')\n",
    "quiz = pd.read_csv('quiz.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Name Columns (53 total)\n",
    "alphabet = list(string.ascii_lowercase)\n",
    "alphabet2 = alphabet + [l+l for l in alphabet] + ['aaa']\n",
    "\n",
    "train.columns = alphabet2\n",
    "# Leave out label column for test data\n",
    "quiz.columns = alphabet2[:-1]\n",
    "\n",
    "# Designate Boolean Columns (15 total)\n",
    "boolean_cols = [\n",
    "    'g', 'p', 'q', 's',\n",
    "    'v', 'w', 'y', 'z',\n",
    "    'oo', 'pp', 'qq', 'rr',\n",
    "    'xx', 'yy', 'zz'\n",
    "]\n",
    "\n",
    "zero_one_two_cols = ['aa','bb','cc','dd','ee','ff','gg','hh','ii','jj','kk','ll','mm','nn']\n",
    "\n",
    "# Designate Categorical Columns (16 total)\n",
    "cols = train.columns\n",
    "num_cols = train._get_numeric_data().columns\n",
    "list(set(cols) - set(num_cols))\n",
    "\n",
    "categorical_cols = ['a', 'c', 'd', 'e', 'f', 'h', 'i', 'j', 'k',\n",
    " 'l', 'm', 'n', 'o', \n",
    "   'ss', 'tt', 'uu'\n",
    " ]\n",
    "\n",
    "for col in categorical_cols:\n",
    "    train[col] = train[col].astype('category')\n",
    "    quiz[col] = quiz[col].astype('category')\n",
    "\n",
    "# Designate Numeric Columns (37 total)\n",
    "numeric_cols = ['b', 'g', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y',\n",
    "       'z', 'aa', 'bb', 'cc', 'dd', 'ee', 'ff', 'gg', 'hh', 'ii',\n",
    "       'jj', 'kk', 'll', 'mm', 'nn', 'oo', 'pp', 'qq', 'rr', 'vv',\n",
    "       'ww', 'xx', 'yy', 'zz']\n",
    "\n",
    "continuous_cols = ['vv', 'ww']\n",
    "\n",
    "numeric_indices = []\n",
    "for i, letter in enumerate(alphabet2):\n",
    "    if letter in numeric_cols:\n",
    "        numeric_indices.append(i)\n",
    "    \n",
    "# [1, 6, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
    "# 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 47, 48, 49, 50, 51, 52]\n",
    "\n",
    "train_labels = np.array(train['aaa']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25367, 5587)\n"
     ]
    }
   ],
   "source": [
    "##########################################\n",
    "#          TheMapTaskClassifier          #\n",
    "##########################################\n",
    "\n",
    "\n",
    "class MetaClassifier:\n",
    "    def __init__(self):    \n",
    "        self.clf1 = KNeighborsClassifier()\n",
    "        self.clf2 = LogisticRegression()\n",
    "        self.clf3 = RandomForestClassifier(n_estimators=100, max_features=50, max_depth=200)\n",
    "        self.clf4 = AdaBoostClassifier()\n",
    "        self.clf5 = GaussianNB()\n",
    "        \n",
    "\n",
    "    def fit(self, train_data_1, train_data_2, train_data_3, train_data_4, train_data_5, train_labels):\n",
    "        self.clf1_trained = self.clf1.fit(train_data_1, train_labels)\n",
    "        print('clf1 fitted')\n",
    "#         self.clf2_trained = self.clf2.fit(train_data_2, train_labels)\n",
    "#         print('clf2 fitted')\n",
    "        self.clf3_trained = self.clf3.fit(train_data_3, train_labels)\n",
    "        print('clf3 fitted')\n",
    "        self.clf4_trained = self.clf4.fit(train_data_4, train_labels)\n",
    "        print('clf4 fitted')\n",
    "        self.clf5_trained = self.clf5.fit(train_data_5, train_labels)\n",
    "        print('clf5 fitted')\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def predict(self, x_test_1, x_test_2, x_test_3, x_test_4, x_test_5):\n",
    "        preds1 = self.clf1.predict(x_test_1)\n",
    "        print('clf1 predicted')\n",
    "#         preds2 = self.clf2.predict(x_test_2)\n",
    "#         print('clf2 predicted')\n",
    "        preds3 = self.clf3.predict(x_test_3)\n",
    "        print('clf3 predicted')\n",
    "        preds4 = self.clf4.predict(x_test_4)\n",
    "        print('clf4 predicted')\n",
    "        preds5 = self.clf5.predict(x_test_5)\n",
    "        print('clf5 predicted')\n",
    "    \n",
    "        # Take sum and round pred results across all clf\n",
    "        preds = np.sum(np.vstack([preds1,preds3,preds4,preds5]), axis=0)\n",
    "        preds[preds >= 0] = 1\n",
    "        preds[preds < 0] = -1\n",
    "        \n",
    "        return preds\n",
    "    \n",
    "    def get_params(self, deep=False):\n",
    "        '''\n",
    "        Hack to make scikit happy when using this class in scikitlearn.cross_val_score\n",
    "        '''\n",
    "        return {}\n",
    "\n",
    "\n",
    "    \n",
    "x_train, x_test, y_train, y_test = train_test_split(train, train.ix[:,-1], train_size=0.2, test_size=0.1)\n",
    "\n",
    "\n",
    "train_dummies = pd.get_dummies(x_train[categorical_cols + zero_one_two_cols + boolean_cols])\n",
    "quiz_dummies = pd.get_dummies(x_test[categorical_cols + zero_one_two_cols + boolean_cols])\n",
    "\n",
    "train_dummies = train_dummies[[col for col in train_dummies.columns if col in quiz_dummies.columns]]\n",
    "quiz_dummies = quiz_dummies[[col for col in quiz_dummies.columns if col in train_dummies.columns]]\n",
    "\n",
    "print(np.array(train_dummies).shape)\n",
    "a = MetaClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25367, 2)\n",
      "(12684, 2)\n",
      "clf1 fitted\n",
      "clf3 fitted\n",
      "clf4 fitted\n",
      "clf5 fitted\n",
      "clf1 predicted\n",
      "clf3 predicted\n",
      "clf4 predicted\n",
      "clf5 predicted\n",
      "(12684,)\n",
      "(12684,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train[continuous_cols].shape)\n",
    "print(x_test[continuous_cols].shape)\n",
    "\n",
    "a.fit(\n",
    "    x_train[continuous_cols],\n",
    "    x_train[continuous_cols],\n",
    "    train_dummies,\n",
    "    train_dummies,\n",
    "    train_dummies,\n",
    "    x_train.ix[:,-1]\n",
    ")\n",
    "\n",
    "train_preds = a.predict(\n",
    "    x_test[continuous_cols],\n",
    "    x_test[continuous_cols],\n",
    "    quiz_dummies,\n",
    "    quiz_dummies,\n",
    "    quiz_dummies\n",
    ")\n",
    "\n",
    "print(train_preds.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.264269946389\n"
     ]
    }
   ],
   "source": [
    "err = (train_preds - y_test).sum() * 1.0 / len(train_preds)\n",
    "\n",
    "print(err)\n",
    "\n",
    "# KNN, GNB & RF\n",
    "# on cont, cat_dum & cat_dum\n",
    "# 0.1452% error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_results(preds):\n",
    "    with open('test_predictions.csv', 'wb') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        writer.writerow(['id', 'Prediction'])\n",
    "        for i, pred in enumerate(preds):\n",
    "            writer.writerow([i+1, pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Peter's method\n",
    "\n",
    "X_dummies = pd.get_dummies(task[categorical_cols + zero_one_two_cols + boolean_cols])\n",
    "X_quiz_dummies = pd.get_dummies(quiz[categorical_cols + zero_one_two_cols + boolean_cols])\n",
    "\n",
    "X_train_dummies = X_dummies[[col for col in X_dummies.columns if col in X_quiz_dummies.columns]]\n",
    "X_quiz_dummies = X_quiz_dummies[[col for col in X_quiz_dummies.columns if col in X_train_dummies.columns]]\n",
    "\n",
    "# Added class weights b/c we're overpredicting on the -1's\n",
    "clf = RandomForestClassifier(max_depth=200, max_features=1, n_estimators=500, class_weight={-1: 1, 1: 2}, n_jobs=-1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_train_dummies, task.ix[:,-1], test_size=0.4)\n",
    "clf_trained = clf.fit(x_train, y_train)\n",
    "scores = cross_val_score(clf_trained, x_test, y_test, cv=5)\n",
    "print(scores)\n",
    "# [0.92550256 0.92313756 0.927959 0.92667061 0.92312241] (before class weighting)\n",
    "# [0.92047694 0.92056766 0.91682271 0.91652705 0.91257638] (after class weighting) (worse)\n",
    "return\n",
    "\n",
    "clf_full_trained = clf.fit(X_train_dummies, task.ix[:,-1])\n",
    "preds = clf_full_trained.predict(X_quiz_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = clf_trained.predict(x_test)\n",
    "print(confusion_matrix(y_test, preds, labels=[-1, 1]))\n",
    "\n",
    "# Before class weighting\n",
    "#  [27476   986]\n",
    "#  [ 2401 19872]\n",
    "\n",
    "# After class weighting\n",
    "# [26350  2116]\n",
    "# [ 1730 20539]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(preds)\n",
    "write_results(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StandardScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-dfbdf2bf2ae8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Normalizing data (just numeric columns)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumeric_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtest_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumeric_cols\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'StandardScaler' is not defined"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "### Tweaking and tuning ###\n",
    "###########################\n",
    "\n",
    "# Normalizing data (just numeric columns)\n",
    "train_std = StandardScaler().fit_transform(train[numeric_cols])\n",
    "test_std = StandardScaler().fit_transform(test[numeric_cols[:-1]])\n",
    "\n",
    "train_std = pandas.DataFrame(data=train_std[0:,0:])\n",
    "test_std = pandas.DataFrame(data=test_std[0:,0:])\n",
    "\n",
    "train_std.columns = numeric_cols\n",
    "# Leave out label column for test data\n",
    "test_std.columns = numeric_cols[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sel = VarianceThreshold(threshold=(.8))\n",
    "reduced_features_train = sel.fit_transform(train_std)\n",
    "\n",
    "rfe = RFE(estimator=LogisticRegression(), n_features_to_select=7, step=1)\n",
    "rfe.fit(train[numeric_cols], train['aaa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check out coorelation matrix of vars\n",
    "train.corr()\n",
    "\n",
    "# Notable correlations with 'aaa' label:\n",
    "# q 9%\n",
    "# aa 20%\n",
    "# bb 17%\n",
    "# vv 41%\n",
    "# ww 41%\n",
    "\n",
    "coorelated_features = ['q', 'aa', 'bb', 'vv', 'ww']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_std' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c1d8ce7bfb12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check out covariance matrix of vars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_std\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcov_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print(df)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_std' is not defined"
     ]
    }
   ],
   "source": [
    "# Check out covariance matrix of vars\n",
    "cov = np.cov(train_std.T)\n",
    "cov_df = pandas.DataFrame(data=cov)\n",
    "# print(df)\n",
    "\n",
    "# Print in sorted order\n",
    "s = cov_df.unstack()\n",
    "so = s.order(kind=\"quicksort\")\n",
    "print(so)\n",
    "\n",
    "# Notable findings:\n",
    "# cols 9, 5 -> 100% coorelation\n",
    "# cols 2 + 3, 29 -> 62%, 48%\n",
    "# cols 1 + 2, 9 -> -76%, -60% \n",
    "# 27, 28 - 41%\n",
    "# 2 + 3, 28 + 29\n",
    "# 31, 32 - 99%\n",
    "# 33, 34, - 89%\n",
    "# 31 + 32, 36 - 41%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
