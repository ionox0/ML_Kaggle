{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "# Classification utils\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Set ipython's max row / column display\n",
    "pd.set_option('display.max_row', 20)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "\n",
    "task = pandas.read_csv('data.csv')\n",
    "quiz = pandas.read_csv('quiz.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Name Columns (53 total)\n",
    "alphabet = list(string.ascii_lowercase)\n",
    "alphabet2 = alphabet + [l+l for l in alphabet] + ['aaa']\n",
    "\n",
    "task.columns = alphabet2\n",
    "# Leave out label column for test data\n",
    "quiz.columns = alphabet2[:-1]\n",
    "\n",
    "# Designate Boolean Columns (15 total)\n",
    "boolean_cols = [\n",
    "    'g', 'p', 'q', 's',\n",
    "    'v', 'w', 'y', 'z',\n",
    "    'oo', 'pp', 'qq', 'rr',\n",
    "    'xx', 'yy', 'zz'\n",
    "]\n",
    "\n",
    "zero_one_two_cols = ['aa','bb','cc','dd','ee','ff','gg','hh','ii','jj','kk','ll','mm','nn']\n",
    "\n",
    "# Designate Categorical Columns (16 total)\n",
    "cols = task.columns\n",
    "num_cols = task._get_numeric_data().columns\n",
    "list(set(cols) - set(num_cols))\n",
    "\n",
    "categorical_cols = ['a', 'c', 'd', 'e', 'f', 'h', 'i', 'j', 'k',\n",
    " 'l', 'm', 'n', 'o', \n",
    "   'ss', 'tt', 'uu'\n",
    " ]\n",
    "\n",
    "for col in categorical_cols:\n",
    "    task[col] = task[col].astype('category')\n",
    "    quiz[col] = quiz[col].astype('category')\n",
    "\n",
    "# Designate Numeric Columns (37 total)\n",
    "numeric_cols = ['b', 'g', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y',\n",
    "       'z', 'aa', 'bb', 'cc', 'dd', 'ee', 'ff', 'gg', 'hh', 'ii',\n",
    "       'jj', 'kk', 'll', 'mm', 'nn', 'oo', 'pp', 'qq', 'rr', 'vv',\n",
    "       'ww', 'xx', 'yy', 'zz']\n",
    "\n",
    "numeric_indices = []\n",
    "for i, letter in enumerate(alphabet2):\n",
    "    if letter in numeric_cols:\n",
    "        numeric_indices.append(i)\n",
    "    \n",
    "# [1, 6, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
    "# 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 47, 48, 49, 50, 51, 52]\n",
    "\n",
    "train_labels = np.array(task['aaa']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "#          TheMapTaskClassifier          #\n",
    "##########################################\n",
    "\n",
    "# VotingClassifier doesn't let us use different classifiers on different columns,\n",
    "# they all have to work on all cols...\n",
    "\n",
    "class MetaClassifier:\n",
    "    def __init__(self):\n",
    "        self.numeric_cols = ['b', 'g', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y',\n",
    "           'z', 'aa', 'bb', 'cc', 'dd', 'ee', 'ff', 'gg', 'hh', 'ii',\n",
    "           'jj', 'kk', 'll', 'mm', 'nn', 'oo', 'pp', 'qq', 'rr', 'vv',\n",
    "           'ww', 'xx', 'yy', 'zz']\n",
    "        \n",
    "        self.categorical_cols = ['a', 'c', 'e', 'd', 'f',\n",
    "            'uu', 'i', 'k', 'j', 'm', 'l', 'o', 'n', 'ss', 'h', 'tt']\n",
    "        \n",
    "        self.actual_numeric_cols = ['vv', 'ww']\n",
    "        \n",
    "        self.boolean_cols = [\n",
    "            'g', 'p', 'q', 's',\n",
    "            'v', 'w', 'y', 'z',\n",
    "            'oo', 'pp', 'qq', 'rr',\n",
    "            'xx', 'yy', 'zz']\n",
    "        \n",
    "        self.clf1 = KNeighborsClassifier()\n",
    "        self.clf2 = RandomForestClassifier()\n",
    "        self.clf3 = GaussianNB()\n",
    "        \n",
    "\n",
    "    def fit(self, train_data, train_labels):\n",
    "        enc_train = encode_as_labels(train_data[categorical_cols])\n",
    "        self.clf1_trained = self.clf1.fit(train_data[self.numeric_cols], train_labels)\n",
    "        self.clf2_trained = self.clf2.fit(train_data[self.numeric_cols], train_labels)\n",
    "        self.clf3_trained = self.clf3.fit(enc_train, train_labels)\n",
    "        return self\n",
    "        \n",
    "    def predict(self, data):\n",
    "        enc_test = pandas.get_dummies(data[categorical_cols])\n",
    "        \n",
    "        preds1 = self.clf1.predict(data[numeric_cols])\n",
    "        preds2 = self.clf2.predict(data[numeric_cols])\n",
    "        preds3 = self.clf3.predict(enc_test)\n",
    "\n",
    "        preds = np.sum(np.vstack([preds1,preds2,preds3]), axis=0)\n",
    "        preds[preds > 0] = 1\n",
    "        preds[preds < 0] = -1\n",
    "        \n",
    "        return preds\n",
    "    \n",
    "    def get_params(self, deep=False):\n",
    "        '''\n",
    "        Hack to make scikit happy when using this class in scikitlearn.cross_val_score\n",
    "        '''\n",
    "        return {}\n",
    "    \n",
    "\n",
    "def cross_val(clf, train_data, train_labels):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(train_data, train_labels, test_size=0.4)\n",
    "    clf_trained = clf.fit(x_train, y_train)\n",
    "    scores = cross_val_score(clf_trained, x_train, y_train, cv=4, scoring=\"accuracy\")\n",
    "    return scores\n",
    "\n",
    "\n",
    "a = MetaClassifier()\n",
    "preds = cross_val(a, train.ix[:,:-1], train['aaa'])\n",
    "write_results(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Method to convert to one-hot encodings for categorical variables\n",
    "# pd.get_dummies --> returns matrix of every feature, concatenated from all cols, into one feature space\n",
    "def encode_as_labels(X):\n",
    "    output = X.copy()\n",
    "    if X.columns is not None:\n",
    "        for col in X.columns:\n",
    "            output[col] = LabelEncoder().fit_transform(output[col])\n",
    "    else:\n",
    "        for colname,col in output.iteritems():\n",
    "            output[colname] = LabelEncoder().fit_transform(col)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_results(preds):\n",
    "    with open('test_predictions.csv', 'wb') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        writer.writerow(['id', 'Prediction'])\n",
    "        for i, pred in enumerate(preds):\n",
    "            writer.writerow([i+1, pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pandas.get_dummies(train[categorical_cols])\n",
    "c = RandomForestClassifier(max_depth=200, max_features=1, n_estimators=500)\n",
    "# bool_num = np.concatenate([boolean_cols, numeric_cols])\n",
    "x_train, x_test, y_train, y_test = train_test_split(df, train.ix[:,-1], test_size=0.4)\n",
    "clf_trained = c.fit(x_train, y_train)\n",
    "cross_val_score(clf_trained, x_test, y_test, cv=5) # array([ 0.91741564,  0.91528364]) - v. good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = RandomForestClassifier(max_depth=200, max_features=1, n_estimators=500)\n",
    "\n",
    "train_df = pandas.get_dummies(train[categorical_cols])\n",
    "clf_trained = c.fit(train_df, train.ix[:,-1])\n",
    "\n",
    "# Figure out how to add empty columns for 1783 cols in train_df that aren't in test_df\n",
    "test_df = pandas.get_dummies(test[categorical_cols])\n",
    "preds = clf_trained.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.92047694  0.92056766  0.91682271  0.91652705  0.91257638]\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-44-67dc00fa9bd0>, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-44-67dc00fa9bd0>\"\u001b[0;36m, line \u001b[0;32m17\u001b[0m\n\u001b[0;31m    return\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "# Peter's method\n",
    "\n",
    "X_dummies = pd.get_dummies(task[categorical_cols + zero_one_two_cols + boolean_cols])\n",
    "X_quiz_dummies = pd.get_dummies(quiz[categorical_cols + zero_one_two_cols + boolean_cols])\n",
    "\n",
    "X_train_dummies = X_dummies[[col for col in X_dummies.columns if col in X_quiz_dummies.columns]]\n",
    "X_quiz_dummies = X_quiz_dummies[[col for col in X_quiz_dummies.columns if col in X_train_dummies.columns]]\n",
    "\n",
    "# Added class weights b/c we're overpredicting on the -1's\n",
    "clf = RandomForestClassifier(max_depth=200, max_features=1, n_estimators=500, class_weight={-1: 1, 1: 2}, n_jobs=-1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_train_dummies, task.ix[:,-1], test_size=0.4)\n",
    "clf_trained = clf.fit(x_train, y_train)\n",
    "scores = cross_val_score(clf_trained, x_test, y_test, cv=5)\n",
    "print(scores)\n",
    "# [0.92550256 0.92313756 0.927959 0.92667061 0.92312241] (before class weighting)\n",
    "# [0.92047694 0.92056766 0.91682271 0.91652705 0.91257638] (after class weighting) (worse)\n",
    "return\n",
    "\n",
    "clf_full_trained = clf.fit(X_train_dummies, task.ix[:,-1])\n",
    "preds = clf_full_trained.predict(X_quiz_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26350  2116]\n",
      " [ 1730 20539]]\n"
     ]
    }
   ],
   "source": [
    "preds = clf_trained.predict(x_test)\n",
    "print(confusion_matrix(y_test, preds, labels=[-1, 1]))\n",
    "\n",
    "# Before class weighting\n",
    "#  [27476   986]\n",
    "#  [ 2401 19872]\n",
    "\n",
    "# After class weighting\n",
    "# [26350  2116]\n",
    "# [ 1730 20539]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(preds)\n",
    "write_results(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########################\n",
    "### Tweaking and tuning ###\n",
    "###########################\n",
    "\n",
    "# Normalizing data (just numeric columns)\n",
    "train_std = StandardScaler().fit_transform(train[numeric_cols])\n",
    "test_std = StandardScaler().fit_transform(test[numeric_cols[:-1]])\n",
    "\n",
    "train_std = pandas.DataFrame(data=train_std[0:,0:])\n",
    "test_std = pandas.DataFrame(data=test_std[0:,0:])\n",
    "\n",
    "train_std.columns = numeric_cols\n",
    "# Leave out label column for test data\n",
    "test_std.columns = numeric_cols[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sel = VarianceThreshold(threshold=(.8))\n",
    "reduced_features_train = sel.fit_transform(train_std)\n",
    "\n",
    "rfe = RFE(estimator=LogisticRegression(), n_features_to_select=7, step=1)\n",
    "rfe.fit(train[numeric_cols], train['aaa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check out coorelation matrix of vars\n",
    "train.corr()\n",
    "\n",
    "# Notable correlations with 'aaa' label:\n",
    "# q 9%\n",
    "# aa 20%\n",
    "# bb 17%\n",
    "# vv 41%\n",
    "# ww 41%\n",
    "\n",
    "coorelated_features = ['q', 'aa', 'bb', 'vv', 'ww']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check out covariance matrix of vars\n",
    "cov = np.cov(train_std.T)\n",
    "cov_df = pandas.DataFrame(data=cov)\n",
    "# print(df)\n",
    "\n",
    "# Print in sorted order\n",
    "s = cov_df.unstack()\n",
    "so = s.order(kind=\"quicksort\")\n",
    "print(so)\n",
    "\n",
    "# Notable findings:\n",
    "# cols 9, 5 -> 100% coorelation\n",
    "# cols 2 + 3, 29 -> 62%, 48%\n",
    "# cols 1 + 2, 9 -> -76%, -60% \n",
    "# 27, 28 - 41%\n",
    "# 2 + 3, 28 + 29\n",
    "# 31, 32 - 99%\n",
    "# 33, 34, - 89%\n",
    "# 31 + 32, 36 - 41%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
