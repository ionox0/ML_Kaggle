{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import Lasso\n",
    "import string\n",
    "\n",
    "\n",
    "def load_train():\n",
    "    data = pandas.read_csv('data.csv')\n",
    "    return data\n",
    "\n",
    "def load_test():\n",
    "    data = pandas.read_csv('quiz.csv')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = load_train()\n",
    "test = load_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Name Columns\n",
    "alphabet = list(string.ascii_lowercase)\n",
    "alphabet2 = alphabet + [l+l for l in alphabet] + ['aaa']\n",
    "train.columns = alphabet2\n",
    "\n",
    "# Designate Boolean Columns\n",
    "boolean_cols = [\n",
    "    'g', 'p', 'q', 's',\n",
    "    'v', 'w', 'y', 'z',\n",
    "    'oo', 'pp', 'qq', 'rr',\n",
    "    'xx', 'yy', 'zz'\n",
    "]\n",
    "\n",
    "factor_cols = [\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'b', u'g', u'p', u'q', u'r', u's', u't', u'u', u'v', u'w', u'x', u'y',\n",
      "       u'z', u'aa', u'bb', u'cc', u'dd', u'ee', u'ff', u'gg', u'hh', u'ii',\n",
      "       u'jj', u'kk', u'll', u'mm', u'nn', u'oo', u'pp', u'qq', u'rr', u'vv',\n",
      "       u'ww', u'xx', u'yy', u'zz', u'aaa'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Designate Categorical Columns\n",
    "cols = train.columns\n",
    "num_cols = train._get_numeric_data().columns\n",
    "list(set(cols) - set(num_cols))\n",
    "print(num_cols)\n",
    "\n",
    "categorical_cols = ['a', 'c', 'e', 'd', 'f',\n",
    " 'uu', 'i', 'k', 'j', 'm',\n",
    " 'l', 'o', 'n', 'ss', 'h',\n",
    " 'tt']\n",
    "\n",
    "# Designate Numeric Columns\n",
    "numeric_cols = ['b', 'g', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y',\n",
    "       'z', 'aa', 'bb', 'cc', 'dd', 'ee', 'ff', 'gg', 'hh', 'ii',\n",
    "       'jj', 'kk', 'll', 'mm', 'nn', 'oo', 'pp', 'qq', 'rr', 'vv',\n",
    "       'ww', 'xx', 'yy', 'zz', 'aaa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "\n",
    "model = linear_model.LinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=1)\n",
    "print(\"Training residual sum of squares: %.2f\" % np.mean((model.predict(train_data) - train_labels) ** 2))\n",
    "print(\"Test residual sum of squares: %.2f\" % np.mean((model.predict(test_data) - test_labels) ** 2))\n",
    "\n",
    "\n",
    "clf = linear_model.Lasso(alpha=2)\n",
    "clf.fit(train_data, train_labels)\n",
    "Lasso(alpha=0.1, fit_intercept=True)\n",
    "print(clf.coef_)\n",
    "print(clf.intercept_)\n",
    "\n",
    "\n",
    "h = .02  # Step size in the mesh\n",
    "\n",
    "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                           random_state=1, n_clusters_per_class=1)\n",
    "\n",
    "rng = np.random.RandomState(2)\n",
    "X += 2 * rng.uniform(size=X.shape)\n",
    "linearly_separable = (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_val(cls, train_data, train_labels):\n",
    "    size = math.ceil(train_data.shape[0] / 10)\n",
    "    train_sets = []\n",
    "    for i in range(0, 10):\n",
    "        train_sets.append([train_data[i : i + size], train_labels[i : i + size]])\n",
    "    \n",
    "    error_rates = []\n",
    "    for s in train_sets:\n",
    "        # Remove the data to be used for testing\n",
    "        reduced_train_set = [x for x in train_sets if x is not s]\n",
    "        reduced_train_set_data = [a for l in reduced_train_set for a in l[0]]\n",
    "        reduced_train_set_labels = [a for l in reduced_train_set for a in l[1]]\n",
    "        classifier = cls(reduced_train_set_data, reduced_train_set_labels)\n",
    "        preds = classifier.predict(s[0])\n",
    "        err_rate = np.count_nonzero(preds - s[1]) / (len(s[0]) + 0.0)\n",
    "        error_rates.append(err_rate)\n",
    "    return np.mean(error_rates)\n",
    "\n",
    "\n",
    "def meta_classify(train_data, train_labels, test_data, test_labels):\n",
    "    err_rates = []\n",
    "    \n",
    "    classifiers = [\n",
    "        AvgPerceptronClassifier,\n",
    "        APCExpanded,\n",
    "        LRWrapper,\n",
    "        LRExpandedWrapper,\n",
    "        LDAWrapper,\n",
    "        QDAWrapper,\n",
    "    ]\n",
    "    \n",
    "    categorical_cls = [\n",
    "        DecisionTreeClassifier(max_depth=5),\n",
    "        RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "        SVC(kernel=\"linear\", C=0.025),\n",
    "        AdaBoostClassifier(),\n",
    "        SVC(gamma=2, C=1),\n",
    "        GaussianNB(),\n",
    "    ]\n",
    "\n",
    "    numerical_cls = [\n",
    "        KNeighborsClassifier(3),\n",
    "        LinearDiscriminantAnalysis(),\n",
    "        QuadraticDiscriminantAnalysis(),\n",
    "    ]\n",
    "    \n",
    "    for clf in classifiers:\n",
    "        clf.fit(X_train, y_train)\n",
    "        print(clf.coef_)\n",
    "        score = clf.score(X_test, y_test)\n",
    "    \n",
    "    for cls in classifiers:\n",
    "        e = cross_val(cls, train_data, train_labels)\n",
    "        err_rates.append(e)\n",
    "        print(cls, e)\n",
    "        \n",
    "    best_cls = classifiers[np.argmin(err_rates)]\n",
    "    return best_cls(train_data, train_labels).predict(test_data)\n",
    "            \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        \n",
    "        data = load()\n",
    "        preds = meta_classify(data[0], data[1], data[2], data[3])\n",
    "        print(np.count_nonzero(preds - data[3]) / (len(data[3]) + 0.0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
