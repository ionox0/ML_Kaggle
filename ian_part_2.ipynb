{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas\n",
    "import string\n",
    "\n",
    "# Classification utils\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load\n",
    "train = pandas.read_csv('data.csv')\n",
    "test = pandas.read_csv('quiz.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Name Columns (53 total)\n",
    "alphabet = list(string.ascii_lowercase)\n",
    "alphabet2 = alphabet + [l+l for l in alphabet] + ['aaa']\n",
    "\n",
    "train.columns = alphabet2\n",
    "# Leave out label column for test data\n",
    "test.columns = alphabet2[:-1]\n",
    "\n",
    "# Designate Boolean Columns (15 total)\n",
    "boolean_cols = [\n",
    "    'g', 'p', 'q', 's',\n",
    "    'v', 'w', 'y', 'z',\n",
    "    'oo', 'pp', 'qq', 'rr',\n",
    "    'xx', 'yy', 'zz'\n",
    "]\n",
    "\n",
    "# Designate Categorical Columns (16 total)\n",
    "cols = train.columns\n",
    "num_cols = train._get_numeric_data().columns\n",
    "list(set(cols) - set(num_cols))\n",
    "\n",
    "categorical_cols = ['a', 'c', 'e', 'd', 'f',\n",
    " 'uu', 'i', 'k', 'j', 'm',\n",
    " 'l', 'o', 'n', 'ss', 'h',\n",
    " 'tt']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    train[col] = train[col].astype('category')\n",
    "    test[col] = test[col].astype('category')\n",
    "\n",
    "# Designate Numeric Columns (37 total)\n",
    "numeric_cols = ['b', 'g', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y',\n",
    "       'z', 'aa', 'bb', 'cc', 'dd', 'ee', 'ff', 'gg', 'hh', 'ii',\n",
    "       'jj', 'kk', 'll', 'mm', 'nn', 'oo', 'pp', 'qq', 'rr', 'vv',\n",
    "       'ww', 'xx', 'yy', 'zz']\n",
    "\n",
    "actual_numeric_cols = ['vv', 'ww']\n",
    "\n",
    "numeric_indices = []\n",
    "for i, letter in enumerate(alphabet2):\n",
    "    if letter in numeric_cols:\n",
    "        numeric_indices.append(i)\n",
    "    \n",
    "# [1, 6, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
    "# 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 47, 48, 49, 50, 51, 52]\n",
    "\n",
    "train_labels = np.array(train['aaa']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sel = VarianceThreshold(threshold=(.8))\n",
    "reduced_features_train = sel.fit_transform(train[numeric_cols[:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Features shown to have coorelation with label\n",
    "coorelated_features = ['q', 'aa', 'bb', 'vv', 'ww']\n",
    "# Features selected by Recursive Feature Extraction\n",
    "rfe_selected_numeric_cols = ['x', 'p', 'dd', 'kk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_val(clf, train_data, train_labels):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(train_data, train_labels, test_size=0.4)\n",
    "    clf_trained = clf.fit(x_train, y_train)\n",
    "    scores = cross_val_score(clf_trained, x_train, y_train, cv=2)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Training error using numeric columns\n",
    "\n",
    "# Keep label out of features\n",
    "clf = KNeighborsClassifier()\n",
    "e = cross_val(clf, train[coorelated_features], train_labels)\n",
    "print(e)   # [ 0.76499961  0.76318625]   regular KNN on features that are coorelated with the label --> ~76%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.82042522  0.81784973]\n"
     ]
    }
   ],
   "source": [
    "# Training error using categorical columns\n",
    "\n",
    "# Method to convert to one-hot encodings\n",
    "# pd.get_dummies --> returns matrix of every feature, concatenated from all cols, into one feature space\n",
    "def encode_as_labels(X):\n",
    "    output = X.copy()\n",
    "    if X.columns is not None:\n",
    "        for col in X.columns:\n",
    "            output[col] = LabelEncoder().fit_transform(output[col])\n",
    "    else:\n",
    "        for colname,col in output.iteritems():\n",
    "            output[colname] = LabelEncoder().fit_transform(col)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enc_train = encode_as_labels(train[categorical_cols])\n",
    "r = RandomForestClassifier(n_estimators=100, max_depth=5)\n",
    "\n",
    "e = cross_val(r, enc_train, train_labels)\n",
    "print(e)    # [ 0.82063546  0.81616777]     RandomForest with max_depth=5, one-hot encoded categorical vars --> ~82%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make test predictions using numeric columns\n",
    "trained = KNeighborsClassifier().fit(train[numeric_cols[:-1]], train['aaa'])\n",
    "preds = trained.predict(np.array(test[numeric_cols[:-1]]))\n",
    "write_results(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make test predictions using voting with multiple classifiers\n",
    "enc_train = encode_as_labels(train[categorical_cols])\n",
    "\n",
    "# Make sure not to include the training labels as part of the data that the classifiers are trainined on!\n",
    "# (otherwise will get 100% training prediction accuracy)\n",
    "frames = [train[numeric_cols[:-1]], enc_train]\n",
    "result = pandas.concat(frames, axis=1)\n",
    "\n",
    "poly = PolynomialFeatures(2)\n",
    "result = poly.fit_transform(result)\n",
    "\n",
    "print(train[numeric_cols].shape, train[categorical_cols].shape)\n",
    "print(result.shape)\n",
    "\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1, max_depth=5)\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "eclf = VotingClassifier([('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
    "scores = cross_val_score(eclf, result, train_labels, cv=10, scoring='accuracy')\n",
    "scores  # VotingClassifier with LR, RF, and GNB -->   ~80% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_results(preds):\n",
    "    with open('test_predictions.csv', 'wb') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        writer.writerow(['id', 'Prediction'])\n",
    "        for i, pred in enumerate(preds):\n",
    "            writer.writerow([i+1, pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1, max_depth=5)\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "eclf = VotingClassifier([('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='soft', weights=[1,1,1])\n",
    "\n",
    "enc_train = encode_as_labels(train[categorical_cols])\n",
    "frames = [train[numeric_cols[:-1]], enc_train]\n",
    "train_result = pandas.concat(frames, axis=1)\n",
    "\n",
    "enc_test = encode_as_labels(test[categorical_cols])\n",
    "frames = [test[numeric_cols[:-1]], enc_test]\n",
    "test_result = pandas.concat(frames, axis=1)\n",
    "\n",
    "eclf.fit(train_result, train['aaa'])\n",
    "write_results(eclf.predict(test_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('before rounding: ', array([ 1, -3, -3, ..., -1, -1,  1]))\n",
      "('before rounding: ', array([-1,  3, -3, ...,  3,  3,  3]))\n",
      "('before rounding: ', array([ 1, -3, -3, ...,  1,  3,  1]))\n",
      "('before rounding: ', array([-3,  1,  3, ...,  1, -3, -1]))\n",
      "[ 0.74272049  0.74434984  0.74890933  0.74407359]\n"
     ]
    }
   ],
   "source": [
    "# New method for ensemble classification\n",
    "# VotingClassifier doesn't let us use different classifiers on different columns, they all have to work on all cols...\n",
    "\n",
    "class TheMapTaskClassifier:\n",
    "    def __init__(self):\n",
    "        self.numeric_cols = ['b', 'g', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y',\n",
    "           'z', 'aa', 'bb', 'cc', 'dd', 'ee', 'ff', 'gg', 'hh', 'ii',\n",
    "           'jj', 'kk', 'll', 'mm', 'nn', 'oo', 'pp', 'qq', 'rr', 'vv',\n",
    "           'ww', 'xx', 'yy', 'zz']\n",
    "        \n",
    "        self.categorical_cols = ['a', 'c', 'e', 'd', 'f',\n",
    "            'uu', 'i', 'k', 'j', 'm', 'l', 'o', 'n', 'ss', 'h', 'tt']\n",
    "        \n",
    "        self.actual_numeric_cols = ['vv', 'ww']\n",
    "        \n",
    "        self.boolean_cols = [\n",
    "            'g', 'p', 'q', 's',\n",
    "            'v', 'w', 'y', 'z',\n",
    "            'oo', 'pp', 'qq', 'rr',\n",
    "            'xx', 'yy', 'zz']\n",
    "        \n",
    "        self.clf1 = LogisticRegression(random_state=1)\n",
    "        self.clf2 = RandomForestClassifier(random_state=1, max_depth=5)\n",
    "        self.clf3 = GaussianNB()\n",
    "        \n",
    "\n",
    "    def fit(self, train_data, train_labels):\n",
    "        enc_train = encode_as_labels(train_data[categorical_cols])\n",
    "        self.clf1_trained = self.clf1.fit(train_data[self.numeric_cols], train_labels)\n",
    "        self.clf2_trained = self.clf2.fit(train_data[self.numeric_cols], train_labels)\n",
    "        self.clf3_trained = self.clf3.fit(enc_train, train_labels)\n",
    "        return self\n",
    "        \n",
    "    def predict(self, data):\n",
    "        enc_test = encode_as_labels(data[categorical_cols])\n",
    "        \n",
    "        preds1 = clf1.predict(data[numeric_cols])\n",
    "        preds2 = clf2.predict(data[numeric_cols])\n",
    "        preds3 = clf3.predict(enc_test)\n",
    "\n",
    "        preds = np.sum(np.vstack([preds1,preds2,preds3]), axis=0)\n",
    "        print('before rounding: ', preds)\n",
    "        preds[preds > 0] = 1\n",
    "        preds[preds < 0] = -1\n",
    "        \n",
    "        return preds\n",
    "    \n",
    "    def get_params(self, deep=False):\n",
    "        '''\n",
    "        Hack to make scikit happy when using this class in scikitlearn.cross_val_score\n",
    "        '''\n",
    "        return {}\n",
    "    \n",
    "\n",
    "def cross_val(clf, train_data, train_labels):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(train_data, train_labels, test_size=0.4)\n",
    "    clf_trained = clf.fit(x_train, y_train)\n",
    "    scores = cross_val_score(clf_trained, x_train, y_train, cv=4, scoring=\"accuracy\")\n",
    "    return scores\n",
    "\n",
    "\n",
    "a = TheMapTaskClassifier()\n",
    "preds = cross_val(a, train.ix[:,:-1], train['aaa'])\n",
    "print(preds)\n",
    "write_results(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1 = np.arange(9.0).reshape((3, 3))\n",
    "x2 = np.arange(3.0)\n",
    "\n",
    "print(x1)\n",
    "print(x2)\n",
    "np.add(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_results(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
